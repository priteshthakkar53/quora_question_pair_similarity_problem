{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import distance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from wordcloud import STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('quora_train.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid1_count = df_train['qid1'].value_counts().to_dict()\n",
    "qid2_count = df_train['qid2'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('quora_test.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>375001</td>\n",
       "      <td>243548</td>\n",
       "      <td>505985</td>\n",
       "      <td>Why do I feel stressed with no reason behind?</td>\n",
       "      <td>I feel stressed, pressured and lonely. Can any...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187485</td>\n",
       "      <td>285732</td>\n",
       "      <td>285733</td>\n",
       "      <td>Can I charge the two 12v DC batteries that pow...</td>\n",
       "      <td>I have a 2.5KVA inverter with two 12v 200AH ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49537</td>\n",
       "      <td>88159</td>\n",
       "      <td>88160</td>\n",
       "      <td>How do I delete the Facebook Messenger account...</td>\n",
       "      <td>How can I delete a Facebook messenger account ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36302</td>\n",
       "      <td>66208</td>\n",
       "      <td>66209</td>\n",
       "      <td>What is a symbol?</td>\n",
       "      <td>What is symbolic programming?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77252</td>\n",
       "      <td>131935</td>\n",
       "      <td>131936</td>\n",
       "      <td>Is it possible to change your class schedule i...</td>\n",
       "      <td>Should high school classes be optional?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0  375001  243548  505985      Why do I feel stressed with no reason behind?   \n",
       "1  187485  285732  285733  Can I charge the two 12v DC batteries that pow...   \n",
       "2   49537   88159   88160  How do I delete the Facebook Messenger account...   \n",
       "3   36302   66208   66209                                  What is a symbol?   \n",
       "4   77252  131935  131936  Is it possible to change your class schedule i...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  I feel stressed, pressured and lonely. Can any...             0  \n",
       "1  I have a 2.5KVA inverter with two 12v 200AH ba...             0  \n",
       "2  How can I delete a Facebook messenger account ...             1  \n",
       "3                      What is symbolic programming?             0  \n",
       "4            Should high school classes be optional?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qid1_counts(col):\n",
    "    cnt = qid1_count.get(col, 0)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qid2_counts(col):\n",
    "    cnt = qid2_count.get(col, 0)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('quora_test_fe_without_preprocessing.csv'):\n",
    "    df = pd.read_csv('quora_test.csv', encoding='latin-1')\n",
    "    df = df.fillna('')\n",
    "    \n",
    "    #qid1_freq: frequency of qid1\n",
    "    df['qid1_freq'] = df['qid1'].apply(lambda x: get_qid1_counts(x))\n",
    "    \n",
    "    #qid2_freq: frequency of qid2\n",
    "    df['qid2_freq'] = df['qid2'].apply(lambda x: get_qid2_counts(x))\n",
    "    \n",
    "    #q1_len: length of question1\n",
    "    df['q1_len'] = df['question1'].str.len()\n",
    "    \n",
    "    #q2_len: length of question2\n",
    "    df['q2_len'] = df['question2'].str.len()\n",
    "    \n",
    "    #q1_n_words: number of words in question1\n",
    "    df['q1_n_words'] = df['question1'].apply(lambda row: len(row.split(' ')))\n",
    "    \n",
    "    #q2_n_words: number of words in question2\n",
    "    df['q2_n_words'] = df['question2'].apply(lambda row: len(row.split(' ')))\n",
    "    \n",
    "    #common_words: number of common unique words in question1 and question2\n",
    "    def normalized_common_words(row):\n",
    "        w1 = set(map(lambda row: row.lower().strip(), row['question1'].split(' ')))\n",
    "        w2 = set(map(lambda row: row.lower().strip(), row['question2'].split(' ')))\n",
    "        return 1.0 * len(w1 & w2)\n",
    "    df['common_words'] = df.apply(normalized_common_words, axis=1)\n",
    "    \n",
    "    #total_words: total number of words in question1 and question2\n",
    "    def normalized_word_total(row):\n",
    "        w1 = set(map(lambda row: row.lower().strip(), row['question1'].split(' ')))\n",
    "        w2 = set(map(lambda row: row.lower().strip(), row['question2'].split(' ')))\n",
    "        return 1.0 * (len(w1) + len(w2))\n",
    "    df['total_words'] = df.apply(normalized_word_total, axis=1)\n",
    "    \n",
    "    #shared_words: common_words/total_words\n",
    "    df['shared_words'] = df['common_words']/df['total_words']\n",
    "    \n",
    "    #qid1+qid2_freq: sum of frequencies of qid1 and qid2\n",
    "    df['qid1+qid2_freq'] = df['qid1_freq']+df['qid2_freq']\n",
    "    \n",
    "    #qid1-qid2_freq: absolute difference of frequencies of qid1 and qid2\n",
    "    df['qid1-qid2_freq'] = abs(df['qid1_freq']-df['qid2_freq'])\n",
    "    \n",
    "    df.to_csv('quora_test_fe_without_preprocessing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAFE_DIV = 0.0001\n",
    "STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "def pre_process(col):\n",
    "    col = str(col).lower()\n",
    "    col = col.replace(\",000,000\", \"m\")\\\n",
    "        .replace(\",000\", \"k\")\\\n",
    "        .replace(\"′\", \"'\")\\\n",
    "        .replace(\"’\", \"'\")\\\n",
    "        .replace(\"won't\", \"will not\")\\\n",
    "        .replace(\"cannot\", \"can not\")\\\n",
    "        .replace(\"can't\", \"can not\")\\\n",
    "        .replace(\"n't\", \" not\")\\\n",
    "        .replace(\"what's\", \"what is\")\\\n",
    "        .replace(\"it's\", \"it is\")\\\n",
    "        .replace(\"'ve\", \" have\")\\\n",
    "        .replace(\"i'm\", \"i am\")\\\n",
    "        .replace(\"'re\", \" are\")\\\n",
    "        .replace(\"he's\", \"he is\")\\\n",
    "        .replace(\"she's\", \"she is\")\\\n",
    "        .replace(\"'s\", \" own\")\\\n",
    "        .replace(\"%\", \" percent \")\\\n",
    "        .replace(\"₹\", \" rupee \")\\\n",
    "        .replace(\"$\", \" dollar \")\\\n",
    "        .replace(\"€\", \" euro \")\\\n",
    "        .replace(\"'ll\", \" will\")\n",
    "    \n",
    "    col = re.sub(r\"([0-9]+)000000\", r\"\\1m\", col)\n",
    "    col = re.sub(r\"([0-9]+)000\", r\"\\1k\", col)\n",
    "    \n",
    "    porter = PorterStemmer()\n",
    "    \n",
    "    # '\\W' matches any non aplhanumeric charecter\n",
    "    pattern = re.compile('\\W')\n",
    "    \n",
    "    if type(col)==type(''):\n",
    "        col = re.sub(pattern, ' ', col)\n",
    "    \n",
    "    if type(col)==type(''):\n",
    "        col=porter.stem(col)\n",
    "        text = BeautifulSoup(col)\n",
    "        col = text.get_text()\n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_features(q1, q2):\n",
    "    \n",
    "    # create a list of size 10 and initialize each element with 0\n",
    "    token_features = [0.0]*10\n",
    "    \n",
    "    # convert sentence to tokens\n",
    "    q1_tokens = q1.split(' ')\n",
    "    q2_tokens = q2.split(' ')\n",
    "    \n",
    "    if len(q1_tokens)==0 or len(q2_tokens)==0:\n",
    "        return token_features\n",
    "    \n",
    "    # get words other than stopwords\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    # get stopwords\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    \n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    common_words_count = len(q1_words.intersection(q2_words))\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # cwc_min: ratio of common words to minimum length of word count of question1 and question2\n",
    "    token_features[0] = common_words_count/(min(len(q1_words),len(q2_words))+SAFE_DIV)\n",
    "    # cwc_max: ratio of common words to maximum length of word count of question1 and question2\n",
    "    token_features[1] = common_words_count/(max(len(q1_words),len(q2_words))+SAFE_DIV)\n",
    "    \n",
    "    # csc_min: ratio of common stop words to minimum length of stop count of question1 and question2\n",
    "    token_features[2] = common_stop_count/(min(len(q1_stops),len(q2_stops))+SAFE_DIV)\n",
    "    # csc_max: ratio of common stop words to maximum length of stop count of question1 and question2\n",
    "    token_features[3] = common_stop_count/(max(len(q1_stops),len(q2_stops))+SAFE_DIV)\n",
    "    \n",
    "    # ctc_min: ratio of common token words to minimum length of token count of question1 and question2\n",
    "    token_features[4] = common_token_count/(min(len(q1_tokens),len(q2_tokens))+SAFE_DIV)\n",
    "    # ctc_max: ratio of common token words to maximum length of token count of question1 and question2\n",
    "    token_features[5] = common_token_count/(max(len(q1_tokens),len(q2_tokens))+SAFE_DIV)\n",
    "    \n",
    "    # last_word_eq\n",
    "    token_features[6] = int(q1_tokens[-1]==q2_tokens[-1])\n",
    "    \n",
    "    # first_word_eq\n",
    "    token_features[7] = int(q1_tokens[0]==q2_tokens[0])\n",
    "    \n",
    "    # abs_len_diff\n",
    "    token_features[8] = abs(len(q1_tokens)-len(q2_tokens))\n",
    "    \n",
    "    # mean_length\n",
    "    token_features[9] = (len(q1_tokens)+len(q2_tokens))/2\n",
    "    \n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# longest_substr_ratio: len(longest common substring) / (min(len(q1_tokens), len(q2_tokens)))\n",
    "def get_longest_substr_ratio(a, b):\n",
    "    strs = list(distance.lcsubstrings(a,b))\n",
    "    if len(strs)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(strs[0])/min(len(a),len(b),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    df['question1'] = df['question1'].apply(pre_process)\n",
    "    df['question2'] = df['question2'].apply(pre_process)\n",
    "    \n",
    "    token_features = df.apply(lambda x: get_token_features(x['question1'],x['question2']), axis=1)\n",
    "    \n",
    "    df['cwc_min']       = list(map(lambda x: x[0], token_features))\n",
    "    df['cwc_max']       = list(map(lambda x: x[1], token_features))\n",
    "    df['csc_min']       = list(map(lambda x: x[2], token_features))\n",
    "    df['csc_max']       = list(map(lambda x: x[3], token_features))\n",
    "    df['ctc_min']       = list(map(lambda x: x[4], token_features))\n",
    "    df['ctc_max']       = list(map(lambda x: x[5], token_features))\n",
    "    df['last_word_eq']  = list(map(lambda x: x[6], token_features))\n",
    "    df['first_word_eq'] = list(map(lambda x: x[7], token_features))\n",
    "    df['abs_len_diff']  = list(map(lambda x: x[8], token_features))\n",
    "    df['mean_len']      = list(map(lambda x: x[9], token_features))\n",
    "    \n",
    "    df['token_set_ratio']      = df.apply(lambda x: fuzz.token_set_ratio(x['question1'],x['question2']), axis=1)\n",
    "    df['token_sort_ratio']     = df.apply(lambda x: fuzz.token_sort_ratio(x['question1'],x['question2']), axis=1)\n",
    "    df['fuzz_ratio']           = df.apply(lambda x: fuzz.QRatio(x['question1'],x['question2']), axis=1)\n",
    "    df['fuzz_partial_ratio']   = df.apply(lambda x: fuzz.partial_ratio(x['question1'],x['question2']), axis=1)\n",
    "    df['longest_substr_ratio'] = df.apply(lambda x: get_longest_substr_ratio(x['question1'],x['question2']), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('quora_test_fe_nlp.csv'):\n",
    "    df = pd.read_csv('quora_test.csv', encoding='latin-1')\n",
    "    df = df.fillna('')\n",
    "    df = extract_features(df)\n",
    "    df.to_csv('quora_test_fe_nlp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762c5ddfd9a74d0fa65d38fea4ca1ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80858), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('quora_test_tfidf_q1.csv'):\n",
    "    df = pd.read_csv('quora_test.csv', encoding='latin-1')\n",
    "    df = df.fillna('')\n",
    "    \n",
    "    df_train = pd.read_csv('quora_train.csv', encoding='latin-1')\n",
    "    df_train = df_train.fillna('')\n",
    "    \n",
    "    questions = list(df_train['question1']) + list(df_train['question2'])\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf.fit_transform(questions)\n",
    "    word_idf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    sample = nlp('Hi')\n",
    "    \n",
    "    vect_form_1 = []\n",
    "    for que_1 in tqdm_notebook(list(df['question1'])):\n",
    "        tokens_1 = nlp(que_1)\n",
    "        vec_1 = np.zeros([len(sample[0].vector)])\n",
    "        for token_1 in tokens_1:\n",
    "            wv_1 = token_1.vector\n",
    "            try:\n",
    "                idf=word_idf[str(token_1)]\n",
    "            except:\n",
    "                idf=0\n",
    "            vec_1 += wv_1*idf\n",
    "        vect_form_1.append(vec_1)\n",
    "    df['q1_vect_form'] = vect_form_1\n",
    "    df_q1 = pd.DataFrame(df['q1_vect_form'].values.tolist())\n",
    "    df_q1.to_csv('quora_test_tfidf_q1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ac9b6786c9431faab2022dfe848086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80858), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('quora_test_tfidf_q2.csv'):\n",
    "    df = pd.read_csv('quora_test.csv', encoding='latin-1')\n",
    "    df = df.fillna('')\n",
    "    \n",
    "    df_train = pd.read_csv('quora_train.csv', encoding='latin-1')\n",
    "    df_train = df_train.fillna('')\n",
    "    \n",
    "    questions = list(df_train['question1']) + list(df_train['question2'])\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf.fit_transform(questions)\n",
    "    word_idf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    sample = nlp('Hi')\n",
    "    \n",
    "    vect_form_2 = []\n",
    "    for que_2 in tqdm_notebook(list(df['question2'])):\n",
    "        tokens_2 = nlp(que_2)\n",
    "        vec_2 = np.zeros([len(sample[0].vector)])\n",
    "        for token_2 in tokens_2:\n",
    "            wv_2 = token_2.vector\n",
    "            try:\n",
    "                idf=word_idf[str(token_2)]\n",
    "            except:\n",
    "                idf=0\n",
    "            vec_2 += wv_2*idf\n",
    "        vect_form_2.append(vec_2)\n",
    "    df['q2_vect_form'] = vect_form_2\n",
    "    df_q2 = pd.DataFrame(df['q2_vect_form'].values.tolist())\n",
    "    df_q2.to_csv('quora_test_tfidf_q2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('quora_test_final_features.csv'):\n",
    "    \n",
    "    df_fe_wo_pp = pd.read_csv('quora_test_fe_without_preprocessing.csv', encoding='latin-1')\n",
    "    \n",
    "    df_nlp = pd.read_csv('quora_test_fe_nlp.csv', encoding='latin-1')\n",
    "    df_nlp = df_nlp.drop(['qid1', 'qid2', 'question1', 'question2', 'is_duplicate'], axis=1)\n",
    "    \n",
    "    df = df_fe_wo_pp.merge(df_nlp, on='id', how='left')\n",
    "    \n",
    "    df_q1 = pd.read_csv('quora_test_tfidf_q1.csv', encoding='latin-1')\n",
    "    df_q1['id'] = df_fe_wo_pp['id']\n",
    "    \n",
    "    df = df.merge(df_q1, on='id', how='left')\n",
    "    \n",
    "    df_q2 = pd.read_csv('quora_test_tfidf_q2.csv', encoding='latin-1')\n",
    "    df_q2['id'] = df_fe_wo_pp['id']\n",
    "    \n",
    "    df = df.merge(df_q2, on='id', how='left')\n",
    "    \n",
    "    df.to_csv('quora_test_final_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
